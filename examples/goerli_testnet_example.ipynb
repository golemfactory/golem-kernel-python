{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7df523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Golem Factory GmbH\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4524a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example is modification of \"Linear Regression with a Real Dataset\" Notebook from Machine Learning Crash Course created by Google and available here: https://github.com/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_a_real_dataset.ipynb\n",
    "# This exercises is made available under the Apache License Version 2.0. You may obtain a copy of the License here: http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Data Set used in this example contains data drawn from the 1990 U.S. Census. It is also available as part of Machine Learning Crash Course created by Google and available here: https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv \n",
    "# Data Set description is available here: https://developers.google.com/machine-learning/crash-course/california-housing-data-description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771bc67e",
   "metadata": {},
   "source": [
    "Intro Text Goerli - linear regression real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28c5b3-7d0c-476f-aaac-512273ebeaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977df4e-b60c-45ee-ab94-761e10d90dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%budget polygon 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec636a1-7e5b-4e7c-990e-f8f44e86b578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%connect timeout=10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5ee72-354d-47bc-9b6a-4b4e0658bfb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%upload california_housing_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc97602-015f-4100-aa4c-8c69e867b795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "training_df = pd.read_csv(filepath_or_buffer=\"workdir/california_housing_train.csv\")\n",
    "# Scale the label.\n",
    "training_df[\"median_house_value\"] /= 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab8ec6-2dec-4dff-bf30-801d6bd8bf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Describe the topography of the model.\n",
    "  # The topography of a simple linear regression model\n",
    "  # is a single node in a single layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1, \n",
    "                                  input_shape=(1,)))\n",
    "\n",
    "  # Compile the model topography into code that TensorFlow can efficiently\n",
    "  # execute. Configure training to minimize the model's mean squared error. \n",
    "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model        \n",
    "\n",
    "\n",
    "def train_model(model, df, feature, label, epochs, batch_size):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Feed the model the feature and the label.\n",
    "  # The model will train for the specified number of epochs. \n",
    "  history = model.fit(x=df[feature],\n",
    "                      y=df[label],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "  # Gather the trained model's weight and bias.\n",
    "  trained_weight = model.get_weights()[0][0][0]\n",
    "  trained_bias = model.get_weights()[1][0]\n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # Isolate the error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  # To track the progression of training, we're going to take a snapshot\n",
    "  # of the model's root mean squared error at each epoch. \n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
    "  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n",
    "\n",
    "  # Label the axes.\n",
    "  plt.xlabel(feature)\n",
    "  plt.ylabel(label)\n",
    "\n",
    "  # Create a scatter plot from 200 random points of the dataset.\n",
    "  random_examples = training_df.sample(n=200)\n",
    "  plt.scatter(random_examples[feature], random_examples[label])\n",
    "\n",
    "  # Create a red line representing the model. The red line starts\n",
    "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
    "  x0 = 0\n",
    "  y0 = trained_bias\n",
    "  x1 = random_examples[feature].max()\n",
    "  y1 = trained_bias + (trained_weight * x1)  \n",
    "  plt.plot([x0, x1], [y0, y1], c='r')\n",
    "\n",
    "  # Render the scatter plot and the red line.\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8a7df-4428-47e4-aa09-d8f29c29c602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "batch_size = 30\n",
    "\n",
    "# Specify the feature and the label.\n",
    "my_feature = \"total_rooms\"  # the total number of rooms on a specific city block.\n",
    "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
    "# That is, you're going to create a model that predicts house value based \n",
    "# solely on total_rooms.  \n",
    "\n",
    "# Discard any pre-existing version of the model.\n",
    "my_model = None\n",
    "\n",
    "# Invoke the functions.\n",
    "my_model = build_model(learning_rate)\n",
    "weight, bias, epochs, rmse = train_model(my_model, training_df, \n",
    "                                         my_feature, my_label,\n",
    "                                         epochs, batch_size)\n",
    "\n",
    "print(\"\\nThe learned weight for your model is %.4f\" % weight)\n",
    "print(\"The learned bias for your model is %.4f\\n\" % bias )\n",
    "\n",
    "plot_the_model(weight, bias, my_feature, my_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f79af-e4a1-40a6-bee8-a94d4e2a3860",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa09141",
   "metadata": {},
   "source": [
    "TODO: %download plot1.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b332a4-7122-49aa-a06f-b85fe6a154c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_house_values(n, feature, label):\n",
    "  \"\"\"Predict house values based on a feature.\"\"\"\n",
    "\n",
    "  batch = training_df[feature][10000:10000 + n]\n",
    "  predicted_values = my_model.predict_on_batch(x=batch)\n",
    "\n",
    "  print(\"feature   label          predicted\")\n",
    "  print(\"  value   value          value\")\n",
    "  print(\"          in thousand$   in thousand$\")\n",
    "  print(\"--------------------------------------\")\n",
    "  for i in range(n):\n",
    "    print (\"%5.0f %6.0f %15.0f\" % (training_df[feature][10000 + i],\n",
    "                                   training_df[label][10000 + i],\n",
    "                                   predicted_values[i][0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108e4db-3999-48df-a1a3-8b94412a5926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_house_values(10, my_feature, my_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0a0ef-eb7a-4824-8b33-9d0d2106898a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%disconnect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Golem",
   "language": "python",
   "name": "golem"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
